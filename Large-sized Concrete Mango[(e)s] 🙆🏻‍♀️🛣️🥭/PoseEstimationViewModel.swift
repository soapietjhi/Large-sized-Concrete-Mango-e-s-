//
//  PoseEstimationViewModel.swift
//  Large-sized Concrete Mango[(e)s] üôÜüèª‚Äç‚ôÄÔ∏èüõ£Ô∏èü•≠
//
//  Created by Sophie Tjhi on 16/8/25.
//

import SwiftUI
import Vision
import AVFoundation
import Observation

// 1.
struct BodyConnection: Identifiable {
    let id = UUID()
    let from: HumanBodyPoseObservation.JointName
    let to: HumanBodyPoseObservation.JointName
}

@Observable
class PoseEstimationViewModel: NSObject, AVCaptureVideoDataOutputSampleBufferDelegate {

    // 2.
    var detectedBodyParts: [HumanBodyPoseObservation.JointName: CGPoint] = [:]
    var bodyConnections: [BodyConnection] = []
    
    override init() {
        super.init()
        setupBodyConnections()
    }
    
    // 3.
    private func setupBodyConnections() {
        bodyConnections = [
            BodyConnection(from: .nose, to: .neck),
            BodyConnection(from: .neck, to: .rightShoulder),
            BodyConnection(from: .neck, to: .leftShoulder),
            BodyConnection(from: .rightShoulder, to: .rightHip),
            BodyConnection(from: .leftShoulder, to: .leftHip),
            BodyConnection(from: .rightHip, to: .leftHip),
            BodyConnection(from: .rightShoulder, to: .rightElbow),
            BodyConnection(from: .rightElbow, to: .rightWrist),
            BodyConnection(from: .leftShoulder, to: .leftElbow),
            BodyConnection(from: .leftElbow, to: .leftWrist),
            BodyConnection(from: .rightHip, to: .rightKnee),
            BodyConnection(from: .rightKnee, to: .rightAnkle),
            BodyConnection(from: .leftHip, to: .leftKnee),
            BodyConnection(from: .leftKnee, to: .leftAnkle)
        ]
    }

    // 4.
    var task: Task<Void, Never>?
    
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        
        if task != nil { return }
        
        task = Task {
            if let detectedPoints = await processFrame(sampleBuffer) {
                DispatchQueue.main.async {
                    self.detectedBodyParts = detectedPoints
                }
            }
            task = nil
        }
        
    }
    // 5.
        func processFrame(_ sampleBuffer: CMSampleBuffer) async -> [HumanBodyPoseObservation.JointName: CGPoint]? {
            guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return nil }
            
            let request = DetectHumanBodyPoseRequest()
            
            do {
                let results = try await request.perform(on: imageBuffer, orientation: .none)
                if let observation = results.first {
                    return extractPoints(from: observation)
                }
            } catch {
                print("Error processing frame: \(error.localizedDescription)")
            }

            return nil
        }

        // 6.
        private func extractPoints(from observation: HumanBodyPoseObservation) -> [HumanBodyPoseObservation.JointName: CGPoint] {
            var detectedPoints: [HumanBodyPoseObservation.JointName: CGPoint] = [:]
            let humanJoints: [HumanBodyPoseObservation.PoseJointsGroupName] = [.face, .torso, .leftArm, .rightArm, .leftLeg, .rightLeg]
            
            for groupName in humanJoints {
                let jointsInGroup = observation.allJoints(in: groupName)
                for (jointName, joint) in jointsInGroup {
                    if joint.confidence > 0.5 { // Ensuring only high-confidence joints are added
                        let point = joint.location.verticallyFlipped().cgPoint
                        detectedPoints[jointName] = point
                    }
                }
            }
            return detectedPoints
        }
    
// find CGPoint, use pythagoras theorem to find distance between hand and the fruit to decide whether CGPoints match
    
    }
